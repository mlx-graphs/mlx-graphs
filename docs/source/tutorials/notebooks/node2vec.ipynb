{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2vec\n",
    "\n",
    "> [!WARNING]\n",
    "> This tutorial is experimental and requires `mlx_cluster` to be installed which\n",
    "> currently requires mlx 0.18.\n",
    "\n",
    "**Goal:** This tutorial will guide you through implementing node2vec to generate vector embeddings for nodes in a simple undirected graph.\n",
    "\n",
    "**Concepts:** `MLX`, `Node2vec`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import mlx.core as mx\n",
    "from mlx_graphs.datasets import PlanetoidDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this first tutorial, we will use the [PlanetoidDataset](https://chrsmrrs.github.io/datasets/docs/datasets/) collection, which comprises of citation networks for `Cora`, `Pubmed` and `CiteSeer`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `Cora` dataset consisting of **2708** nodes and **10,056** edges. The dataset can be easily accessed via `PlanetoidDataset` class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cora data ... Done\n"
     ]
    }
   ],
   "source": [
    "dataset = PlanetoidDataset(\"Cora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cora(num_graphs=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access dataset properties directly from `dataset`object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset attributes\n",
      "--------------------\n",
      "Number of graphs: 1\n",
      "Number of node features: 1433\n",
      "Number of edge features: 0\n",
      "Number of graph features: 0\n",
      "Number of graph classes to predict: 0\n",
      "\n",
      "Dataset stats\n",
      "--------------------\n",
      "Mean node degree: 3.90\n",
      "Mean num of nodes: 2708.00\n",
      "Mean num of edges: 10556.00\n"
     ]
    }
   ],
   "source": [
    "# Some useful properties\n",
    "print(\"Dataset attributes\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Number of graphs: {len(dataset)}\")\n",
    "print(f\"Number of node features: {dataset.num_node_features}\")\n",
    "print(f\"Number of edge features: {dataset.num_edge_features}\")\n",
    "print(f\"Number of graph features: {dataset.num_graph_features}\")\n",
    "print(f\"Number of graph classes to predict: {dataset.num_graph_classes}\\n\")\n",
    "\n",
    "# Statistics of the dataset\n",
    "stats = defaultdict(list)\n",
    "for g in dataset:\n",
    "    stats[\"Mean node degree\"].append(g.num_edges / g.num_nodes)\n",
    "    stats[\"Mean num of nodes\"].append(g.num_nodes)\n",
    "    stats[\"Mean num of edges\"].append(g.num_edges)\n",
    "\n",
    "print(\"Dataset stats\")\n",
    "print(\"-\" * 20)\n",
    "for k, v in stats.items():\n",
    "    mean = mx.mean(mx.array(v)).item()\n",
    "    print(f\"{k}: {mean:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(\n",
       "\tedge_index(shape=(2, 10556), int32)\n",
       "\tnode_features(shape=(2708, 1433), float32)\n",
       "\tnode_labels(shape=(2708,), int32)\n",
       "\ttrain_mask(shape=(2708,), bool)\n",
       "\tval_mask(shape=(2708,), bool)\n",
       "\ttest_mask(shape=(2708,), bool))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a simple neural network using node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlx_graphs.algorithms import Node2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify hyperparameters for node2vec. \n",
    "\n",
    "The most important hyperparameters for node2vec are `p` and `q` where \n",
    "1. `p` : specifies the likelihood of revisiting a node in the walk (return parameter). When this is low the algorithm is  more likely to take a step back.\n",
    "2. `q` : specifies likelhood of exploring nodes that are further away from the source. When this is high the algorithm is more likely to explore the neighbourhood\n",
    "3. `embedding_dim`: dimemnsions of embedding model\n",
    "4. `walk_length`: Number of nodes to consider in a walk\n",
    "5. `context_size`: The actual context size which is considered for positive samples. This parameter increases the effective sampling rate by reusing samples across different source nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "walk_length = 20\n",
    "context_size = 10\n",
    "walks_per_node = 10\n",
    "num_negative_samples = 1\n",
    "p = 1.0\n",
    "q = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Node2Vec(\n",
    "    edge_index=dataset[0].edge_index,\n",
    "    num_nodes=dataset[0].num_nodes,\n",
    "    embedding_dim=embedding_dim,\n",
    "    walk_length=walk_length,\n",
    "    context_size=context_size,\n",
    "    walks_per_node=walks_per_node,\n",
    "    num_negative_samples=num_negative_samples,\n",
    "    p=p,\n",
    "    q=q,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try and train a simple model loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.optimizers as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = model.dataloader(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a simple training loop to train an embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 batch loss : 2.88000\n",
      "Epoch : 1 batch loss : 2.24894\n",
      "Epoch : 2 batch loss : 2.16864\n",
      "Epoch : 3 batch loss : 2.14403\n",
      "Epoch : 4 batch loss : 2.13199\n",
      "Epoch : 5 batch loss : 2.12255\n",
      "Epoch : 6 batch loss : 2.11843\n",
      "Epoch : 7 batch loss : 2.11297\n",
      "Epoch : 8 batch loss : 2.10973\n",
      "Epoch : 9 batch loss : 2.10481\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    dataloader = model.dataloader(batch_size=32)\n",
    "    for pos, neg in dataloader:\n",
    "        loss, grad = nn.value_and_grad(model, model.loss)(pos, neg)\n",
    "        total_loss+=loss.item()\n",
    "        optimizer.update(model, grad)\n",
    "    print(f\"Epoch : {epoch} batch loss : {total_loss/32:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
