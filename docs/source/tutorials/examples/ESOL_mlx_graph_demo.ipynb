{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de1dc48-49a2-4931-9703-1afd3eda656c",
   "metadata": {},
   "source": [
    "# install rdkit via pip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76671162-76bf-46fe-938c-73d8db74ccd7",
   "metadata": {},
   "source": [
    "!pip install rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec95ed87-8dcf-4b6a-84cd-82a0a6916ee3",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e45ecbc-c976-4fe4-a201-1f21ea3cebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import mlx.core as mx\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlx_graphs.data import GraphData\n",
    "from mlx_graphs.datasets.dataset import Dataset\n",
    "from mlx_graphs.datasets.utils import download\n",
    "from mlx_graphs.utils.transformations import to_sparse_adjacency_matrix\n",
    "from typing import Tuple\n",
    "from typing import Optional\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Lipinski\n",
    "from rdkit.Chem import rdMolDescriptors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3fdb5-7740-4ffa-bf76-4f0c8434ebb6",
   "metadata": {},
   "source": [
    "# get the ESOL source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86dbc3e-26f1-4d50-97e8-185d3a8f22b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ESOL.csv from https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 96.7k/96.7k [00:00<00:00, 321kB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ESOL.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/delaney-processed.csv', path=\"ESOL.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba96b29-05e9-4b0c-bb4d-cdab80057e72",
   "metadata": {},
   "source": [
    "# retreive SMILES and target LogS columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f37b3c-8647-4c99-8eea-360b38a5b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>LogS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)...</td>\n",
       "      <td>-0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1occc1C(=O)Nc2ccccc2</td>\n",
       "      <td>-3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)=CCCC(C)=CC(=O)</td>\n",
       "      <td>-2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43</td>\n",
       "      <td>-7.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1ccsc1</td>\n",
       "      <td>-1.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles  LogS\n",
       "0  OCC3OC(OCC2OC(OC(C#N)c1ccccc1)C(O)C(O)C2O)C(O)... -0.77\n",
       "1                             Cc1occc1C(=O)Nc2ccccc2 -3.30\n",
       "2                               CC(C)=CCCC(C)=CC(=O) -2.06\n",
       "3                 c1ccc2c(c1)ccc3c2ccc4c5ccccc5ccc43 -7.87\n",
       "4                                            c1ccsc1 -1.33"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ESOL.csv')\n",
    "data = data[['smiles','measured log solubility in mols per litre']]\n",
    "data.columns = ['Smiles','LogS']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b62c43-9feb-4bf1-aa28-ec55e85a0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c455b8-e19a-494e-8872-da159af8fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# my c++ official RDkit code to get Atom basic features \n",
    "def _atomFeatures(atom: Chem.Atom,\n",
    "                 ) -> np.array:\n",
    "    return rdMolDescriptors.GetAtomFeatures(atom.GetOwningMol(), atom.GetIdx())\n",
    "\n",
    "# AdjacencyMatrix extractoin and formating\n",
    "def _compute_adjacency(\n",
    "    molecule: Chem.Mol,\n",
    "    dtype: np.dtype = np.int32,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    'Computes adjacency matrix from an RDKit molecule object.'\n",
    "\n",
    "    adjacency = Chem.GetAdjacencyMatrix(molecule)\n",
    "\n",
    "    return adjacency.astype(dtype)\n",
    "\n",
    "# Get Edge_features\n",
    "def generate_bond_features(\n",
    "    mol: Chem.Mol)-> Tuple[np.ndarray, np.ndarray]:\n",
    "    # Dictionaries for mapping bond types and stereochemistry to integers\n",
    "    bond_type_dict = {'SINGLE': 1, 'DOUBLE': 2, 'TRIPLE': 3, 'AROMATIC': 4}\n",
    "    bond_stereo_dict = {'STEREONONE': 0,'STEREOANY': 1, 'STEREOE': 2, 'STEREOZ': 3}\n",
    "    \n",
    "    # Calculate rotatable bonds\n",
    "    rotbonds = Lipinski._RotatableBonds(mol)\n",
    "    \n",
    "    # Initialize a list to store bond features\n",
    "    bond_features = []\n",
    "    \n",
    "    for bond in mol.GetBonds():\n",
    "        # Get the owning molecule (not necessary if `mol` is already given)\n",
    "        mol = bond.GetOwningMol()\n",
    "        \n",
    "        # Get sorted atom indices for the bond\n",
    "        atom_indices = tuple(sorted([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()]))\n",
    "        \n",
    "        # Determine if the bond is rotatable\n",
    "        is_rotatable = atom_indices in rotbonds\n",
    "        \n",
    "        # Get the bond's features\n",
    "        bond_stereo_feature = bond_stereo_dict[bond.GetStereo().name]\n",
    "        bond_type_feature = bond_type_dict[bond.GetBondType().name]\n",
    "        is_conjugated = bond.GetIsConjugated()\n",
    "        \n",
    "        # Append the features as a tuple to the bond_features list\n",
    "        bond_features.append((bond_stereo_feature, bond_type_feature, is_conjugated, is_rotatable))\n",
    "    \n",
    "    return bond_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9029a597-5f8c-42aa-9120-cfd4f46d7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55cd46b-08c8-4682-acd4-283ae37d52f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smiles      C\n",
      "LogS     -0.9\n",
      "Name: 934, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i,row in data.iterrows():\n",
    "    try:\n",
    "        # Get an RDkit Molecule object from Smiles\n",
    "        mol = Chem.MolFromSmiles(row.Smiles.strip())\n",
    "        # Get the edge_indexes (we will overwrite the edge_features)\n",
    "        edge_index, edge_features = to_sparse_adjacency_matrix(mx.array(_compute_adjacency(mol)))\n",
    "        # Get Node features\n",
    "        atf = np.zeros((mol.GetNumAtoms(),49))\n",
    "        for i, atom in enumerate(mol.GetAtoms()):\n",
    "            atf[i,:] = _atomFeatures(atom)\n",
    "        node_features  = mx.array(atf)\n",
    "        # Get Edge features\n",
    "        edge_features = mx.array(generate_bond_features(mol))\n",
    "        # Get the target : \"LogS\"\n",
    "        label =  mx.ones((1, 1))*row.LogS\n",
    "        # append the list of GraphData objects\n",
    "        dataset.append(\n",
    "            GraphData(\n",
    "                \n",
    "                edge_index=edge_index,\n",
    "                node_features=node_features,\n",
    "                edge_features=edge_features,\n",
    "                graph_labels=label, \n",
    "                        )\n",
    "                )\n",
    "    except:\n",
    "        # the \"C\" is a single atom molecule so it is expected to be an exception in this process!\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "337e1f5e-3638-4d13-919d-008f27382cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.522]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9badff58-330e-4727-ab35-beafc71cd33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.522"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.LogS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab264ba8-0cee-4dbd-b9b5-76334438d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(\n",
       "\tedge_index(shape=(2, 68), uint32)\n",
       "\tnode_features(shape=(32, 49), float32)\n",
       "\tedge_features(shape=(34, 4), int32)\n",
       "\tgraph_labels(shape=(1, 1), float32))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958496b8-594a-4646-9d22-5b4960366930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph batch of size 64\n",
      "GraphDataBatch(\n",
      "\tedge_index(shape=(2, 1796), int64)\n",
      "\tnode_features(shape=(869, 49), float32)\n",
      "\tedge_features(shape=(898, 4), int32)\n",
      "\tgraph_labels(shape=(64, 1), float32))\n",
      "array([0, 0, 0, ..., 63, 63, 63], dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "from mlx_graphs.loaders import Dataloader\n",
    "\n",
    "# split is an example not a real value of CV also we need to add the randomization!!!\n",
    "train_dataset = dataset[:1000]\n",
    "test_dataset = dataset[1000:]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = Dataloader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = Dataloader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(f\"\\nGraph batch of size {len(batch)}\")\n",
    "    print(batch)\n",
    "    print(batch.batch_indices)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645b37aa-101e-4d98-8700-600e30f15dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.nn as nn\n",
    "from mlx_graphs.nn import GINConv, global_mean_pool, Linear\n",
    "import time\n",
    "\n",
    "\n",
    "class GINE(nn.Module):\n",
    "    def __init__(self, in_dim_edge, in_dim_node, hidden_dim, out_dim, dropout=0.1):\n",
    "        super(GINE, self).__init__()\n",
    "\n",
    "        self.conv1 = GINConv(\n",
    "            mlp=nn.Sequential(\n",
    "            nn.Linear(in_dim_node, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            ), \n",
    "            #node_features_dim=in_dim_node,\n",
    "            #edge_features_dim=in_dim_edge,\n",
    "        )\n",
    "        self.conv2 = GINConv(\n",
    "            mlp=nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            ), \n",
    "            #node_features_dim=hidden_dim,\n",
    "            #edge_features_dim=hidden_dim,\n",
    "        )\n",
    "        self.conv3 = GINConv(\n",
    "            mlp=nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            ), \n",
    "            #node_features_dim=hidden_dim,\n",
    "            #edge_features_dim=hidden_dim,\n",
    "        )\n",
    "        self.linear = Linear(hidden_dim, out_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def __call__(self, edge_index, node_features, batch_indices):\n",
    "        h = nn.relu(self.conv1(edge_index, node_features))\n",
    "        h = nn.relu(self.conv2(edge_index, h))\n",
    "        h = self.conv3(edge_index, h)\n",
    "        \n",
    "        h = global_mean_pool(h, batch_indices)\n",
    "\n",
    "        h = self.dropout(h)\n",
    "        h = self.linear(h)\n",
    "        \n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166f1992-7b17-4e9b-8b40-2760be346e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_hat, y, parameters=None):\n",
    "    return mx.mean(nn.losses.mse_loss(y_hat, y))\n",
    "\n",
    "def forward_fn(model, graph, labels):\n",
    "    y_hat = model(graph.edge_index, graph.node_features, graph.batch_indices)\n",
    "    loss = loss_fn(y_hat, labels, model.parameters())\n",
    "    return loss, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a532c43-8a84-4e01-b02f-11a7d9bfc32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = mx.gpu # or mx.cpu\n",
    "mx.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "673a3c77-04ef-4eca-8449-7febd1ac6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader):\n",
    "    loss_sum = 0.0\n",
    "    for graph in train_loader:\n",
    "        \n",
    "        (loss, y_hat), grads = loss_and_grad_fn(\n",
    "            model=model,\n",
    "            graph=graph,\n",
    "            labels=graph.graph_labels,\n",
    "        )\n",
    "        optimizer.update(model, grads)\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "        loss_sum += loss.item()\n",
    "    return loss_sum / len(train_loader.dataset)\n",
    "\n",
    "def test(test_loader):\n",
    "    mse= 0.0\n",
    "    for graph in test_loader:\n",
    "        y_hat = model(graph.edge_index, graph.node_features, graph.batch_indices)\n",
    "        mse += mx.square(y_hat - graph.graph_labels).sum().item()\n",
    "    \n",
    "    return mse / len(test_loader.dataset)\n",
    "\n",
    "def epoch():\n",
    "    loss = train(train_loader)\n",
    "    train_mse = test(train_loader)\n",
    "    test_mse = test(test_loader)\n",
    "    return loss, train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e17ed94b-08c1-4896-9c9c-b4069369798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.optimizers as optim\n",
    "mx.random.seed(42)\n",
    "\n",
    "model = GINE(\n",
    "    in_dim_node=dataset[0].node_features.shape[1],\n",
    "    in_dim_edge=dataset[0].edge_features.shape[1],\n",
    "    hidden_dim=64,\n",
    "    out_dim=1,\n",
    ")\n",
    "mx.eval(model.parameters())\n",
    "\n",
    "optimizer = optim.Adam(learning_rate=0.001)\n",
    "loss_and_grad_fn = nn.value_and_grad(model, forward_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "272b8095-3066-4a19-a4fe-4232d8dd4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 | Train loss: 0.119 | Train mse: 2.813 | Test mse: 2.645\n",
      "Epoch:   1 | Train loss: 0.050 | Train mse: 2.465 | Test mse: 2.499\n",
      "Epoch:   2 | Train loss: 0.034 | Train mse: 1.838 | Test mse: 2.281\n",
      "Epoch:   3 | Train loss: 0.029 | Train mse: 1.692 | Test mse: 1.969\n",
      "Epoch:   4 | Train loss: 0.024 | Train mse: 1.315 | Test mse: 1.636\n",
      "Epoch:   5 | Train loss: 0.023 | Train mse: 1.364 | Test mse: 1.574\n",
      "Epoch:   6 | Train loss: 0.024 | Train mse: 1.138 | Test mse: 1.500\n",
      "Epoch:   7 | Train loss: 0.019 | Train mse: 1.059 | Test mse: 1.356\n",
      "Epoch:   8 | Train loss: 0.016 | Train mse: 0.905 | Test mse: 1.223\n",
      "Epoch:   9 | Train loss: 0.017 | Train mse: 0.957 | Test mse: 1.122\n",
      "Epoch:  10 | Train loss: 0.015 | Train mse: 0.813 | Test mse: 0.932\n",
      "Epoch:  11 | Train loss: 0.013 | Train mse: 0.757 | Test mse: 0.983\n",
      "Epoch:  12 | Train loss: 0.013 | Train mse: 0.727 | Test mse: 1.004\n",
      "Epoch:  13 | Train loss: 0.014 | Train mse: 0.715 | Test mse: 0.842\n",
      "Epoch:  14 | Train loss: 0.014 | Train mse: 0.835 | Test mse: 1.034\n",
      "Epoch:  15 | Train loss: 0.012 | Train mse: 0.678 | Test mse: 0.970\n",
      "Epoch:  16 | Train loss: 0.011 | Train mse: 0.618 | Test mse: 0.868\n",
      "Epoch:  17 | Train loss: 0.010 | Train mse: 0.584 | Test mse: 0.849\n",
      "Epoch:  18 | Train loss: 0.011 | Train mse: 0.586 | Test mse: 0.832\n",
      "Epoch:  19 | Train loss: 0.011 | Train mse: 0.542 | Test mse: 0.760\n",
      "Epoch:  20 | Train loss: 0.010 | Train mse: 0.553 | Test mse: 0.803\n",
      "Epoch:  21 | Train loss: 0.010 | Train mse: 0.722 | Test mse: 0.879\n",
      "Epoch:  22 | Train loss: 0.010 | Train mse: 0.493 | Test mse: 0.691\n",
      "Epoch:  23 | Train loss: 0.010 | Train mse: 0.516 | Test mse: 0.603\n",
      "Epoch:  24 | Train loss: 0.008 | Train mse: 0.550 | Test mse: 0.729\n",
      "Epoch:  25 | Train loss: 0.008 | Train mse: 0.481 | Test mse: 0.745\n",
      "Epoch:  26 | Train loss: 0.008 | Train mse: 0.465 | Test mse: 0.658\n",
      "Epoch:  27 | Train loss: 0.007 | Train mse: 0.441 | Test mse: 0.621\n",
      "Epoch:  28 | Train loss: 0.008 | Train mse: 0.477 | Test mse: 0.689\n",
      "Epoch:  29 | Train loss: 0.008 | Train mse: 0.490 | Test mse: 0.600\n",
      "Epoch:  30 | Train loss: 0.007 | Train mse: 0.432 | Test mse: 0.680\n",
      "Epoch:  31 | Train loss: 0.007 | Train mse: 0.452 | Test mse: 0.514\n",
      "Epoch:  32 | Train loss: 0.007 | Train mse: 0.398 | Test mse: 0.601\n",
      "Epoch:  33 | Train loss: 0.007 | Train mse: 0.386 | Test mse: 0.617\n",
      "Epoch:  34 | Train loss: 0.007 | Train mse: 0.372 | Test mse: 0.605\n",
      "Epoch:  35 | Train loss: 0.006 | Train mse: 0.390 | Test mse: 0.514\n",
      "Epoch:  36 | Train loss: 0.006 | Train mse: 0.390 | Test mse: 0.556\n",
      "Epoch:  37 | Train loss: 0.007 | Train mse: 0.681 | Test mse: 0.837\n",
      "Epoch:  38 | Train loss: 0.009 | Train mse: 0.504 | Test mse: 0.656\n",
      "Epoch:  39 | Train loss: 0.007 | Train mse: 0.392 | Test mse: 0.550\n",
      "Epoch:  40 | Train loss: 0.007 | Train mse: 0.355 | Test mse: 0.541\n",
      "Epoch:  41 | Train loss: 0.006 | Train mse: 0.445 | Test mse: 0.569\n",
      "Epoch:  42 | Train loss: 0.006 | Train mse: 0.370 | Test mse: 0.608\n",
      "Epoch:  43 | Train loss: 0.006 | Train mse: 0.395 | Test mse: 0.579\n",
      "Epoch:  44 | Train loss: 0.005 | Train mse: 0.323 | Test mse: 0.613\n",
      "Epoch:  45 | Train loss: 0.006 | Train mse: 0.373 | Test mse: 0.516\n",
      "Epoch:  46 | Train loss: 0.007 | Train mse: 0.375 | Test mse: 0.564\n",
      "Epoch:  47 | Train loss: 0.006 | Train mse: 0.457 | Test mse: 0.737\n",
      "Epoch:  48 | Train loss: 0.007 | Train mse: 0.358 | Test mse: 0.519\n",
      "Epoch:  49 | Train loss: 0.007 | Train mse: 0.542 | Test mse: 0.718\n",
      "Epoch:  50 | Train loss: 0.006 | Train mse: 0.310 | Test mse: 0.517\n",
      "Epoch:  51 | Train loss: 0.006 | Train mse: 0.289 | Test mse: 0.501\n",
      "Epoch:  52 | Train loss: 0.006 | Train mse: 0.338 | Test mse: 0.552\n",
      "Epoch:  53 | Train loss: 0.006 | Train mse: 0.324 | Test mse: 0.502\n",
      "Epoch:  54 | Train loss: 0.006 | Train mse: 0.319 | Test mse: 0.556\n",
      "Epoch:  55 | Train loss: 0.005 | Train mse: 0.284 | Test mse: 0.451\n",
      "Epoch:  56 | Train loss: 0.005 | Train mse: 0.285 | Test mse: 0.514\n",
      "Epoch:  57 | Train loss: 0.006 | Train mse: 0.465 | Test mse: 0.635\n",
      "Epoch:  58 | Train loss: 0.006 | Train mse: 0.339 | Test mse: 0.510\n",
      "Epoch:  59 | Train loss: 0.005 | Train mse: 0.284 | Test mse: 0.487\n",
      "Epoch:  60 | Train loss: 0.005 | Train mse: 0.318 | Test mse: 0.538\n",
      "Epoch:  61 | Train loss: 0.005 | Train mse: 0.291 | Test mse: 0.531\n",
      "Epoch:  62 | Train loss: 0.005 | Train mse: 0.349 | Test mse: 0.497\n",
      "Epoch:  63 | Train loss: 0.005 | Train mse: 0.338 | Test mse: 0.576\n",
      "Epoch:  64 | Train loss: 0.005 | Train mse: 0.282 | Test mse: 0.475\n",
      "Epoch:  65 | Train loss: 0.005 | Train mse: 0.268 | Test mse: 0.452\n",
      "Epoch:  66 | Train loss: 0.005 | Train mse: 0.377 | Test mse: 0.503\n",
      "Epoch:  67 | Train loss: 0.005 | Train mse: 0.275 | Test mse: 0.531\n",
      "Epoch:  68 | Train loss: 0.005 | Train mse: 0.308 | Test mse: 0.466\n",
      "Epoch:  69 | Train loss: 0.005 | Train mse: 0.466 | Test mse: 0.736\n",
      "Epoch:  70 | Train loss: 0.007 | Train mse: 0.261 | Test mse: 0.547\n",
      "Epoch:  71 | Train loss: 0.007 | Train mse: 0.301 | Test mse: 0.523\n",
      "Epoch:  72 | Train loss: 0.006 | Train mse: 0.296 | Test mse: 0.553\n",
      "Epoch:  73 | Train loss: 0.004 | Train mse: 0.285 | Test mse: 0.521\n",
      "Epoch:  74 | Train loss: 0.005 | Train mse: 0.275 | Test mse: 0.507\n",
      "Epoch:  75 | Train loss: 0.004 | Train mse: 0.272 | Test mse: 0.523\n",
      "Epoch:  76 | Train loss: 0.004 | Train mse: 0.252 | Test mse: 0.463\n",
      "Epoch:  77 | Train loss: 0.004 | Train mse: 0.266 | Test mse: 0.438\n",
      "Epoch:  78 | Train loss: 0.004 | Train mse: 0.297 | Test mse: 0.533\n",
      "Epoch:  79 | Train loss: 0.004 | Train mse: 0.249 | Test mse: 0.503\n",
      "Epoch:  80 | Train loss: 0.004 | Train mse: 0.297 | Test mse: 0.497\n",
      "Epoch:  81 | Train loss: 0.004 | Train mse: 0.295 | Test mse: 0.590\n",
      "Epoch:  82 | Train loss: 0.004 | Train mse: 0.267 | Test mse: 0.456\n",
      "Epoch:  83 | Train loss: 0.004 | Train mse: 0.255 | Test mse: 0.467\n",
      "Epoch:  84 | Train loss: 0.004 | Train mse: 0.232 | Test mse: 0.472\n",
      "Epoch:  85 | Train loss: 0.004 | Train mse: 0.236 | Test mse: 0.440\n",
      "Epoch:  86 | Train loss: 0.004 | Train mse: 0.224 | Test mse: 0.520\n",
      "Epoch:  87 | Train loss: 0.005 | Train mse: 0.290 | Test mse: 0.564\n",
      "Epoch:  88 | Train loss: 0.005 | Train mse: 0.256 | Test mse: 0.524\n",
      "Epoch:  89 | Train loss: 0.004 | Train mse: 0.210 | Test mse: 0.454\n",
      "Epoch:  90 | Train loss: 0.004 | Train mse: 0.239 | Test mse: 0.455\n",
      "Epoch:  91 | Train loss: 0.004 | Train mse: 0.245 | Test mse: 0.504\n",
      "Epoch:  92 | Train loss: 0.004 | Train mse: 0.225 | Test mse: 0.462\n",
      "Epoch:  93 | Train loss: 0.004 | Train mse: 0.218 | Test mse: 0.487\n",
      "Epoch:  94 | Train loss: 0.004 | Train mse: 0.234 | Test mse: 0.491\n",
      "Epoch:  95 | Train loss: 0.004 | Train mse: 0.370 | Test mse: 0.583\n",
      "Epoch:  96 | Train loss: 0.004 | Train mse: 0.214 | Test mse: 0.504\n",
      "Epoch:  97 | Train loss: 0.004 | Train mse: 0.224 | Test mse: 0.518\n",
      "Epoch:  98 | Train loss: 0.004 | Train mse: 0.201 | Test mse: 0.429\n",
      "Epoch:  99 | Train loss: 0.004 | Train mse: 0.208 | Test mse: 0.486\n",
      "\n",
      "==> Best test mse: 0.429\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 100\n",
    "best_test_mse = 1e9\n",
    "for e in range(epochs):\n",
    "    loss, train_mse, test_mse = epoch()\n",
    "    best_test_mse = min(best_test_mse, test_mse)\n",
    "\n",
    "    print(\n",
    "        \" | \".join(\n",
    "            [\n",
    "                f\"Epoch: {e:3d}\",\n",
    "                f\"Train loss: {loss:.3f}\",\n",
    "                f\"Train mse: {train_mse:.3f}\",\n",
    "                f\"Test mse: {test_mse:.3f}\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "print(f\"\\n==> Best test mse: {best_test_mse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ad39f-c5fc-418a-8252-fb197a88ab55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
